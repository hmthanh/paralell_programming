{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập thực hành 1 : Làm mờ ảnh RGB\n",
    "\n",
    "**Thông tin sinh viên** :\n",
    "\n",
    "Hoàng Minh Thanh (18424062)\n",
    "\n",
    "Jupyter notebook (Online) : https://colab.research.google.com/drive/17TOLU6_vHtm0Bl_joh1VszJj1GNcZ3oJ#scrollTo=XFEzNQBb2wHF\n",
    "\n",
    "Thực hiện chạy trên Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Thu_Jun_11_22:26:48_Pacific_Daylight_Time_2020\n",
      "Cuda compilation tools, release 11.0, V11.0.194\n",
      "Build cuda_11.0_bu.relgpu_drvr445TC445_37.28540450_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
      "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to c:\\users\\thanh\\appdata\\local\\temp\\pip-req-build-wg6cyjgb\n",
      "Building wheels for collected packages: NVCCPlugin\n",
      "  Building wheel for NVCCPlugin (setup.py): started\n",
      "  Building wheel for NVCCPlugin (setup.py): finished with status 'done'\n",
      "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4344 sha256=38d4e275f075073b50e8f876e3105b76887a905a0a28649c50a4ecc0d3329c69\n",
      "  Stored in directory: C:\\Users\\Thanh\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-6y_xpyus\\wheels\\c5\\2b\\c0\\87008e795a14bbcdfc7c846a00d06981916331eb980b6c8bdf\n",
      "Successfully built NVCCPlugin\n",
      "Installing collected packages: NVCCPlugin\n",
      "Successfully installed NVCCPlugin-0.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git 'C:\\Users\\Thanh\\AppData\\Local\\Temp\\pip-req-build-wg6cyjgb'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created output directory at D:\\Workspace\\paralell_programming\\Practical_1\\src\n",
      "Out bin D:\\Workspace\\paralell_programming\\Practical_1\\result.out\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-b51edbb310c7>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-b51edbb310c7>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    using namespace std;\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "// ############### COMMON ###############\n",
    "#define CHECK(call)                                                        \\\n",
    "{                                                                          \\\n",
    "    const cudaError_t error = call;                                        \\\n",
    "    if (error != cudaSuccess)                                              \\\n",
    "    {                                                                      \\\n",
    "        printf(\"Error: %s:%d, \", __FILE__, __LINE__);                      \\\n",
    "        printf(\"code:%d, reason: %s\\n\", error, cudaGetErrorString(error)); \\\n",
    "        exit(1);                                                           \\\n",
    "    }                                                                      \\\n",
    "}\n",
    "\n",
    "inline double seconds()\n",
    "{\n",
    "    struct timeval tp;\n",
    "    struct timezone tzp;\n",
    "    int i = gettimeofday(&tp, &tzp);\n",
    "    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n",
    "}\n",
    "\n",
    "void initialData(double *data, int size)\n",
    "// Khởi tạo vector ban đầu có kích thước size, kiểu double và giá random trong khoảng [0, 1]\n",
    "{\n",
    "    srand(0);\n",
    "    for (int i = 0; i < size; i++)\n",
    "    {\n",
    "        data[i] = (double)(rand()) / RAND_MAX;\n",
    "    }\n",
    "}\n",
    "\n",
    "double sumGPU(double *data, int size){\n",
    "    double sum = 0;\n",
    "    for(int i = 0; i < size; i++){\n",
    "        sum += data[i];\n",
    "    }\n",
    "\n",
    "    return sum;\n",
    "}\n",
    "\n",
    "// ############### Device(CPU) ###############\n",
    "// Hàm thực hiện reduce trên CPU\n",
    "double recursiveReduce(double *data, int const size)\n",
    "{\n",
    "    if (size == 1) return data[0];\n",
    "  \n",
    "    int const stride = size / 2;\n",
    "    for (int i = 0; i < stride; i++){\n",
    "        data[i] += data[i + stride];\n",
    "    }\n",
    "    \n",
    "    return recursiveReduce(data, stride);\n",
    "}\n",
    "\n",
    "// ############### Device(GPU) ###############\n",
    "// Neighbored Pair phân kỳ\n",
    "__global__ void reduceNeighbored (double *g_idata, double *g_odata,\n",
    "    unsigned int n)\n",
    "{\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // Chuyển từ con trỏ toàn cục sang con trỏ của block này\n",
    "    double *idata = g_idata + blockIdx.x * blockDim.x;\n",
    "\n",
    "    // Kiểm tra nếu vượt qua kích thước mảng\n",
    "    if (idx >= n) return;\n",
    "\n",
    "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
    "    for (int stride = 1; stride < blockDim.x; stride *= 2)\n",
    "    {\n",
    "        if ((tid % (2 * stride)) == 0)\n",
    "        {\n",
    "            idata[tid] += idata[tid + stride];\n",
    "        }\n",
    "\n",
    "        // Đồng bộ hóa trong một threadBlock\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    // Ghi kết quả cho block này vào bộ nhớ toàn cục\n",
    "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
    "}\n",
    "\n",
    "// Neighbored Pair cài đặt với ít phân kỳ bằng cách thực thi trong một block\n",
    "__global__ void reduceNeighboredLess (double *g_idata, double *g_odata,\n",
    "    unsigned int n)\n",
    "{\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // Chuyển từ con trỏ toàn cục sang con trỏ của block này\n",
    "    double *idata = g_idata + blockIdx.x * blockDim.x;\n",
    "\n",
    "    // Kiểm tra nếu vượt qua kích thước mảng\n",
    "    if(idx >= n) return;\n",
    "\n",
    "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
    "    for (int stride = 1; stride < blockDim.x; stride *= 2)\n",
    "    {\n",
    "        // Chuyển tid sang bộ nhớ của một block (register - thanh ghi)\n",
    "        int index = 2 * stride * tid;\n",
    "\n",
    "        if (index < blockDim.x)\n",
    "        {\n",
    "            idata[index] += idata[index + stride];\n",
    "        }\n",
    "\n",
    "        // Đồng bộ hóa trong một threadBlock\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    // Ghi kết quả cho block này vào bộ nhớ toàn cục\n",
    "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
    "}\n",
    "\n",
    "// Interleaved Pair Implementation with less divergence\n",
    "__global__ void reduceInterleaved (double *g_idata, double *g_odata, unsigned int n)\n",
    "{\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // Chuyển từ con trỏ toàn cục sang con trỏ của block này\n",
    "    double *idata = g_idata + blockIdx.x * blockDim.x;\n",
    "\n",
    "    // Kiểm tra nếu vượt qua kích thước mảng\n",
    "    if(idx >= n) return;\n",
    "\n",
    "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
    "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
    "    {\n",
    "        if (tid < stride)\n",
    "        {\n",
    "            idata[tid] += idata[tid + stride];\n",
    "        }\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    // Ghi kết quả cho block này vào bộ nhớ toàn cục\n",
    "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
    "}\n",
    "\n",
    "__global__ void reduceUnrolling2 (double *g_idata, double *g_odata,\n",
    "    unsigned int n)\n",
    "{\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int idx = blockIdx.x * blockDim.x * 2 + threadIdx.x;\n",
    "\n",
    "    // Chuyển từ con trỏ toàn cục sang con trỏ của block này\n",
    "    double *idata = g_idata + blockIdx.x * blockDim.x * 2;\n",
    "\n",
    "    // unrolling 2 data blocks\n",
    "    if (idx + blockDim.x < n) g_idata[idx] += g_idata[idx + blockDim.x];\n",
    "    // Đồng bộ hóa các group data trong 2 thread kết cận\n",
    "    __syncthreads();\n",
    "\n",
    "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
    "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
    "    {\n",
    "        if (tid < stride)\n",
    "        {\n",
    "            idata[tid] += idata[tid + stride];\n",
    "        }\n",
    "\n",
    "        // Đồng bộ hóa trong một threadBlock\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    // Ghi kết quả cho block này vào bộ nhớ toàn cục\n",
    "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
    "}\n",
    "\n",
    "__global__ void reduceUnrolling4(double *g_idata, double *g_odata, unsigned int n){\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int idx = blockIdx.x * blockDim.x * 4 + threadIdx.x;\n",
    "\n",
    "    // Chuyển từ con trỏ toàn cục sang con trỏ của block này\n",
    "    double *idata = g_idata + blockIdx.x * blockDim.x * 4;\n",
    "\n",
    "    // unrolling 4\n",
    "    if (idx + 3 * blockDim.x < n)\n",
    "    {\n",
    "        double a1 = g_idata[idx];\n",
    "        double a2 = g_idata[idx + blockDim.x];\n",
    "        double a3 = g_idata[idx + 2 * blockDim.x];\n",
    "        double a4 = g_idata[idx + 3 * blockDim.x];\n",
    "        g_idata[idx] = a1 + a2 + a3 + a4;\n",
    "    }\n",
    "    __syncthreads(); // Đồng bộ hóa các group data trong 4 thread kết cận\n",
    "\n",
    "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
    "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
    "    {\n",
    "        if (tid < stride)\n",
    "        {\n",
    "            idata[tid] += idata[tid + stride];\n",
    "        }\n",
    "\n",
    "        // Đồng bộ hóa trong một threadBlock\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    // Ghi kết quả cho block này vào bộ nhớ toàn cục\n",
    "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
    "}\n",
    "\n",
    "__global__ void reduceUnrolling8 (double *g_idata, double *g_odata, unsigned int n){\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
    "    double *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
    "\n",
    "    // unrolling 8\n",
    "    if (idx + 7 * blockDim.x < n)\n",
    "    {\n",
    "        double a1 = g_idata[idx];\n",
    "        double a2 = g_idata[idx + blockDim.x];\n",
    "        double a3 = g_idata[idx + 2 * blockDim.x];\n",
    "        double a4 = g_idata[idx + 3 * blockDim.x];\n",
    "        double b1 = g_idata[idx + 4 * blockDim.x];\n",
    "        double b2 = g_idata[idx + 5 * blockDim.x];\n",
    "        double b3 = g_idata[idx + 6 * blockDim.x];\n",
    "        double b4 = g_idata[idx + 7 * blockDim.x];\n",
    "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
    "    }\n",
    "    __syncthreads(); // Đồng bộ hóa các group data trong 8 thread kết cận\n",
    "\n",
    "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
    "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1){\n",
    "        if (tid < stride){\n",
    "            idata[tid] += idata[tid + stride];\n",
    "        }\n",
    "\n",
    "        // Đồng bộ hóa trong một threadBlock\n",
    "        __syncthreads();\n",
    "    }\n",
    "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
    "}\n",
    "\n",
    "__global__ void reduceUnrollWarps8 (double *g_idata, double *g_odata, unsigned int n)\n",
    "{\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
    "    double *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
    "\n",
    "    if (idx + 7 * blockDim.x < n)\n",
    "    {\n",
    "        double a1 = g_idata[idx];\n",
    "        double a2 = g_idata[idx + blockDim.x];\n",
    "        double a3 = g_idata[idx + 2 * blockDim.x];\n",
    "        double a4 = g_idata[idx + 3 * blockDim.x];\n",
    "        double b1 = g_idata[idx + 4 * blockDim.x];\n",
    "        double b2 = g_idata[idx + 5 * blockDim.x];\n",
    "        double b3 = g_idata[idx + 6 * blockDim.x];\n",
    "        double b4 = g_idata[idx + 7 * blockDim.x];\n",
    "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
    "    }\n",
    "    __syncthreads();\n",
    "\n",
    "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
    "    for (int stride = blockDim.x / 2; stride > 32; stride >>= 1){\n",
    "        if (tid < stride){\n",
    "            idata[tid] += idata[tid + stride];\n",
    "        }\n",
    "\n",
    "        // Đồng bộ hóa trong một threadBlock\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    // unrolling warp\n",
    "    if (tid < 32)\n",
    "    {\n",
    "        volatile double *vmem = idata;\n",
    "        vmem[tid] += vmem[tid + 32];\n",
    "        vmem[tid] += vmem[tid + 16];\n",
    "        vmem[tid] += vmem[tid +  8];\n",
    "        vmem[tid] += vmem[tid +  4];\n",
    "        vmem[tid] += vmem[tid +  2];\n",
    "        vmem[tid] += vmem[tid +  1];\n",
    "    }\n",
    "\n",
    "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
    "}\n",
    "\n",
    "__global__ void reduceCompleteUnrollWarps8 (double *g_idata, double *g_odata,\n",
    "        unsigned int n){\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
    "    double *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
    "\n",
    "    if (idx + 7 * blockDim.x < n)\n",
    "    {\n",
    "        double a1 = g_idata[idx];\n",
    "        double a2 = g_idata[idx + blockDim.x];\n",
    "        double a3 = g_idata[idx + 2 * blockDim.x];\n",
    "        double a4 = g_idata[idx + 3 * blockDim.x];\n",
    "        double b1 = g_idata[idx + 4 * blockDim.x];\n",
    "        double b2 = g_idata[idx + 5 * blockDim.x];\n",
    "        double b3 = g_idata[idx + 6 * blockDim.x];\n",
    "        double b4 = g_idata[idx + 7 * blockDim.x];\n",
    "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
    "    }\n",
    "    __syncthreads(); // Đồng bộ hóa tất cả các thread trong một block\n",
    "\n",
    "    // in-place reduction and complete unroll\n",
    "    if (blockDim.x >= 1024 && tid < 512) idata[tid] += idata[tid + 512];\n",
    "    __syncthreads();\n",
    "\n",
    "    if (blockDim.x >= 512 && tid < 256) idata[tid] += idata[tid + 256];\n",
    "    __syncthreads();\n",
    "\n",
    "    if (blockDim.x >= 256 && tid < 128) idata[tid] += idata[tid + 128];\n",
    "    __syncthreads();\n",
    "\n",
    "    if (blockDim.x >= 128 && tid < 64) idata[tid] += idata[tid + 64];\n",
    "    __syncthreads();\n",
    "\n",
    "    // unrolling warp\n",
    "    if (tid < 32)\n",
    "    {\n",
    "        volatile double *vsmem = idata;\n",
    "        vsmem[tid] += vsmem[tid + 32];\n",
    "        vsmem[tid] += vsmem[tid + 16];\n",
    "        vsmem[tid] += vsmem[tid +  8];\n",
    "        vsmem[tid] += vsmem[tid +  4];\n",
    "        vsmem[tid] += vsmem[tid +  2];\n",
    "        vsmem[tid] += vsmem[tid +  1];\n",
    "    }\n",
    "\n",
    "    // Ghi kết quả cho block này vào bộ nhớ toàn cục\n",
    "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
    "}\n",
    "\n",
    "template <unsigned int iBlockSize>\n",
    "__global__ void reduceCompleteUnroll(double *g_idata, double *g_odata,\n",
    "                                     unsigned int n)\n",
    "{\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
    "\n",
    "    // Chuyển từ con trỏ toàn cục sang con trỏ của block này\n",
    "    double *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
    "\n",
    "    // unrolling 8\n",
    "    if (idx + 7 * blockDim.x < n)\n",
    "    {\n",
    "        double a1 = g_idata[idx];\n",
    "        double a2 = g_idata[idx + blockDim.x];\n",
    "        double a3 = g_idata[idx + 2 * blockDim.x];\n",
    "        double a4 = g_idata[idx + 3 * blockDim.x];\n",
    "        double b1 = g_idata[idx + 4 * blockDim.x];\n",
    "        double b2 = g_idata[idx + 5 * blockDim.x];\n",
    "        double b3 = g_idata[idx + 6 * blockDim.x];\n",
    "        double b4 = g_idata[idx + 7 * blockDim.x];\n",
    "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
    "    }\n",
    "\n",
    "    __syncthreads(); // Đồng bộ tất các thread trong một block\n",
    "\n",
    "    // in-place reduction and complete unroll\n",
    "    if (iBlockSize >= 1024 && tid < 512) idata[tid] += idata[tid + 512];\n",
    "    __syncthreads();\n",
    "\n",
    "    if (iBlockSize >= 512 && tid < 256)  idata[tid] += idata[tid + 256];\n",
    "    __syncthreads();\n",
    "\n",
    "    if (iBlockSize >= 256 && tid < 128)  idata[tid] += idata[tid + 128];\n",
    "    __syncthreads();\n",
    "\n",
    "    if (iBlockSize >= 128 && tid < 64)   idata[tid] += idata[tid + 64];\n",
    "    __syncthreads();\n",
    "\n",
    "    // unrolling warp\n",
    "    if (tid < 32)\n",
    "    {\n",
    "        volatile double *vsmem = idata;\n",
    "        vsmem[tid] += vsmem[tid + 32];\n",
    "        vsmem[tid] += vsmem[tid + 16];\n",
    "        vsmem[tid] += vsmem[tid +  8];\n",
    "        vsmem[tid] += vsmem[tid +  4];\n",
    "        vsmem[tid] += vsmem[tid +  2];\n",
    "        vsmem[tid] += vsmem[tid +  1];\n",
    "    }\n",
    "\n",
    "    // Ghi kết quả cho block này vào bộ nhớ toàn cục\n",
    "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
    "}\n",
    "\n",
    "__global__ void reduceUnrollWarps (double *g_idata, double *g_odata, unsigned int n)\n",
    "{\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int idx = blockIdx.x * blockDim.x * 2 + threadIdx.x;\n",
    "\n",
    "    // Chuyển từ con trỏ toàn cục sang con trỏ của block này\n",
    "    double *idata = g_idata + blockIdx.x * blockDim.x * 2;\n",
    "\n",
    "    // unrolling 2\n",
    "    if (idx + blockDim.x < n) g_idata[idx] += g_idata[idx + blockDim.x];\n",
    "\n",
    "    __syncthreads();\n",
    "\n",
    "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
    "    for (int stride = blockDim.x / 2; stride > 32; stride >>= 1)\n",
    "    {\n",
    "        if (tid < stride)\n",
    "        {\n",
    "            idata[tid] += idata[tid + stride];\n",
    "        }\n",
    "\n",
    "        // Đồng bộ hóa trong một threadBlock\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    // unrolling last warp\n",
    "    if (tid < 32)\n",
    "    {\n",
    "        volatile double *vsmem = idata;\n",
    "        vsmem[tid] += vsmem[tid + 32];\n",
    "        vsmem[tid] += vsmem[tid + 16];\n",
    "        vsmem[tid] += vsmem[tid +  8];\n",
    "        vsmem[tid] += vsmem[tid +  4];\n",
    "        vsmem[tid] += vsmem[tid +  2];\n",
    "        vsmem[tid] += vsmem[tid +  1];\n",
    "    }\n",
    "\n",
    "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    printf(\"############ THÔNG TIN GPU ############\\n\");\n",
    "    // Chọn GPU thực thi câu lệnh    \n",
    "    int dev = 0;\n",
    "    cudaDeviceProp deviceProp;\n",
    "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
    "    printf(\"Device %d: %s \\n\", dev, deviceProp.name);\n",
    "    CHECK(cudaSetDevice(dev));\n",
    "\n",
    "    // Khởi tạo kích thước vector\n",
    "    int size = 1 << 24; // 2^24\n",
    "    printf(\"Kích thước mảng : %d\\n\", size);\n",
    "    \n",
    "    // Kernel được cấu hình với 1D grid và 1D blocks\n",
    "    int const BLOCK_SIZE = 512;\n",
    "    dim3 block (BLOCK_SIZE, 1); // Block size có kích thước 512 x 1 ~ (x, y)\n",
    "    dim3 grid  ((size + block.x - 1) / block.x, 1); // Grid size có kích thước ceil(size/block.x)\n",
    "    printf(\"Kích thước : <<<Grid (%d, %d), Block (%d, %d)>>>\\n\", block.x, block.y, grid.x, grid.y);\n",
    " \n",
    "    // Cấp phát bộ nhớ trên host (CPU)\n",
    "    size_t bytes = size * sizeof(double);\n",
    "    double *h_idata = (double *) malloc(bytes); // host input data\n",
    "    double *h_odata = (double *) malloc(grid.x * sizeof(double)); // host output data\n",
    "    double *temp    = (double *) malloc(bytes); // vùng nhớ tạp để copy input cho nhiều hàm thực thi khác nhau\n",
    " \n",
    "    initialData(h_idata, size);\n",
    "    // Copy vào biến temp để chạy với CPU\n",
    "    memcpy (temp, h_idata, bytes);\n",
    " \n",
    "    // Biến tính thời gian chạy\n",
    "    double iStart, iElaps;\n",
    "    double gpu_sum = 0.0; // hàm tính tổng kết quả trên GPU\n",
    "    double gpu_bytes = grid.x * sizeof(double);\n",
    "\n",
    "    // Cấp phát bộ nhớ trên device (GPU)\n",
    "    double *d_idata = NULL;\n",
    "    double *d_odata = NULL;\n",
    "    CHECK(cudaMalloc(&d_idata, bytes));\n",
    "    CHECK(cudaMalloc(&d_odata, gpu_bytes));\n",
    " \n",
    "    printf(\"ID| Time \\t\\t| Sum result \\t\\t| <<<GridSize, BlockSize >>> | Kernel\\t\\t\\n\");\n",
    "    // ############ 1. CPU #############\n",
    "    iStart = seconds();\n",
    "    double cpu_sum = recursiveReduce (temp, size);\n",
    "    iElaps = seconds() - iStart;\n",
    "    printf(\"1 | %f sec\\t| %f\\t|\\t\\t | recursiveReduce-CPU\\n\", iElaps, cpu_sum);\n",
    "\n",
    "    // ############ 2. reduceNeighbored ############\n",
    "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iStart = seconds();\n",
    "    reduceNeighbored<<<grid, block>>>(d_idata, d_odata, size);\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iElaps = seconds() - iStart;\n",
    "    CHECK(cudaMemcpy(h_odata, d_odata, gpu_bytes, cudaMemcpyDeviceToHost));\n",
    "    gpu_sum = sumGPU(h_odata, grid.x);\n",
    "    printf(\"2 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceNeighbored\\n\", iElaps, gpu_sum, grid.x, block.x);\n",
    "\n",
    "    // ############ 3. reduceNeighboredLess ############\n",
    "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iStart = seconds();\n",
    "    reduceNeighboredLess<<<grid, block>>>(d_idata, d_odata, size);\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iElaps = seconds() - iStart;\n",
    "    CHECK(cudaMemcpy(h_odata, d_odata, gpu_bytes, cudaMemcpyDeviceToHost));\n",
    "    gpu_sum = sumGPU(h_odata, grid.x);\n",
    "    printf(\"3 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceNeighboredLess\\n\", iElaps, gpu_sum, grid.x, block.x);\n",
    "\n",
    "    // ############ 4. reduceInterleaved ############\n",
    "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iStart = seconds();\n",
    "    reduceInterleaved<<<grid, block>>>(d_idata, d_odata, size);\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iElaps = seconds() - iStart;\n",
    "    CHECK(cudaMemcpy(h_odata, d_odata, gpu_bytes, cudaMemcpyDeviceToHost));\n",
    "    gpu_sum = sumGPU(h_odata, grid.x);\n",
    "    printf(\"4 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceInterleaved\\n\", iElaps, gpu_sum, grid.x, block.x);\n",
    "\n",
    "    // ############ 5. reduceUnrolling2 ############\n",
    "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iStart = seconds();\n",
    "    reduceUnrolling2<<<grid.x / 2, block>>>(d_idata, d_odata, size);\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iElaps = seconds() - iStart;\n",
    "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 2 * sizeof(double), cudaMemcpyDeviceToHost));\n",
    "    gpu_sum = sumGPU(h_odata, grid.x / 2);\n",
    "    printf(\"5 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceUnrolling2\\n\", iElaps, gpu_sum, grid.x/2, block.x);\n",
    "\n",
    "    // ############ 6. reduceUnrolling4 ############\n",
    "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iStart = seconds();\n",
    "    reduceUnrolling4<<<grid.x / 4, block>>>(d_idata, d_odata, size);\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iElaps = seconds() - iStart;\n",
    "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 4 * sizeof(double), cudaMemcpyDeviceToHost));\n",
    "    gpu_sum = sumGPU(h_odata, grid.x / 4);\n",
    "    printf(\"6 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceUnrolling4\\n\", iElaps, gpu_sum, grid.x/4, block.x);\n",
    "\n",
    "    // ############ 7. reduceUnrolling8 ############\n",
    "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iStart = seconds();\n",
    "    reduceUnrolling8<<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iElaps = seconds() - iStart;\n",
    "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(double), cudaMemcpyDeviceToHost));\n",
    "    gpu_sum = sumGPU(h_odata, grid.x / 8);\n",
    "    printf(\"7 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceUnrolling8\\n\", iElaps, gpu_sum, grid.x/8, block.x);\n",
    "\n",
    "    // ############ 8. reduceUnrollWarps8 ############\n",
    "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iStart = seconds();\n",
    "    reduceUnrollWarps8<<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iElaps = seconds() - iStart;\n",
    "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(double), cudaMemcpyDeviceToHost));\n",
    "    gpu_sum = sumGPU(h_odata, grid.x / 8);\n",
    "    printf(\"8 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceUnrollWarps8\\n\", iElaps, gpu_sum, grid.x/8, block.x);\n",
    "\n",
    "    // ############ 9. reduceCompleteUnrollWarsp8 ############\n",
    "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iStart = seconds();\n",
    "    reduceCompleteUnrollWarps8<<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iElaps = seconds() - iStart;\n",
    "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(double), cudaMemcpyDeviceToHost));\n",
    "    gpu_sum = sumGPU(h_odata, grid.x / 8);\n",
    "    printf(\"9 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceCompleteUnrollWarsp8\\n\", iElaps, gpu_sum, grid.x/8, block.x);\n",
    "\n",
    "    // ############ 10. reduceCompleteUnroll ############\n",
    "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iStart = seconds();\n",
    "    switch (BLOCK_SIZE){\n",
    "    case 1024:\n",
    "        reduceCompleteUnroll<1024><<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
    "        break;\n",
    "\n",
    "    case 512:\n",
    "        reduceCompleteUnroll<512><<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
    "        break;\n",
    "\n",
    "    case 256:\n",
    "        reduceCompleteUnroll<256><<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
    "        break;\n",
    "\n",
    "    case 128:\n",
    "        reduceCompleteUnroll<128><<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
    "        break;\n",
    "\n",
    "    case 64:\n",
    "        reduceCompleteUnroll<64><<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
    "        break;\n",
    "    }\n",
    "\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    iElaps = seconds() - iStart;\n",
    "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(double), cudaMemcpyDeviceToHost));\n",
    "    gpu_sum = sumGPU(h_odata, grid.x / 8);\n",
    "    printf(\"10| %f sec\\t| %f\\t|<<<%d, %d>>> | reduceCompleteUnroll\\n\", iElaps, gpu_sum, grid.x/8, block.x);\n",
    "\n",
    "    // free host memory\n",
    "    free(h_idata);\n",
    "    free(h_odata);\n",
    "\n",
    "    // free device memory\n",
    "    CHECK(cudaFree(d_idata));\n",
    "    CHECK(cudaFree(d_odata));\n",
    "\n",
    "    // reset device\n",
    "    CHECK(cudaDeviceReset());\n",
    "\n",
    "    // Print sum result\n",
    "    printf(\"Sum on CPU : %f\\nSum on GPU : %f\", cpu_sum, gpu_sum);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
