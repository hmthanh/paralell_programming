{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "18424062_BT5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XFEzNQBb2wHF"
      },
      "source": [
        "# Bài tập 4 : Tính tổng tích luỹ (tt)\n",
        "\n",
        "**Thông tin sinh viên** :\n",
        "\n",
        "Hoàng Minh Thanh (18424062)\n",
        "\n",
        "Jupyter notebook (Online) : https://colab.research.google.com/drive/1tSSxxtJMB9HVTExi8xER_ptkBpg3s-oZ\n",
        "\n",
        "Thực hiện chạy trên Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YF4ioW3H7k_Y"
      },
      "source": [
        "## Cài đặt cấu hình chạy CUDA trên Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48CqrfEDf6Ff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "5288763b-d800-48fb-fa27-ea9432087486"
      },
      "source": [
        "%%bash\n",
        "rm -r /content/*\n",
        "pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-h7m89_he\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py): started\n",
            "  Building wheel for NVCCPlugin (setup.py): finished with status 'done'\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=e21a7148ce158c89866d5d953b65471cda6fd2fa7849796da2856c97b34b76a0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xnqu7lko/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-h7m89_he\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lflYvWi_18A7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eaf51d85-f869-4a7d-ac23-702ba2f965d3"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UfRbHHPLOGR0"
      },
      "source": [
        "## 1. Cài đặt chương trình CUDA\n",
        "\n",
        "### Cài đặt chương trình tổng vector với các hàm khác nhau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDWI2GxJQc_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f2ff41c5-45b0-4203-9e19-c43662b6bc82"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#define RANDOM_MAX 10\n",
        "#define BLOCK_SIZE 512\n",
        "\n",
        "// ############### COMMON ###############\n",
        "#define CHECK(call)                                                        \\\n",
        "{                                                                          \\\n",
        "    const cudaError_t error = call;                                        \\\n",
        "    if (error != cudaSuccess)                                              \\\n",
        "    {                                                                      \\\n",
        "        printf(\"Error: %s:%d, \", __FILE__, __LINE__);                      \\\n",
        "        printf(\"code:%d, reason: %s\\n\", error, cudaGetErrorString(error)); \\\n",
        "        exit(1);                                                           \\\n",
        "    }                                                                      \\\n",
        "}\n",
        "\n",
        "inline double seconds()\n",
        "{\n",
        "    struct timeval tp;\n",
        "    struct timezone tzp;\n",
        "    int i = gettimeofday(&tp, &tzp);\n",
        "    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n",
        "}\n",
        "\n",
        "void initialVector(int *vector, int size)\n",
        "{\n",
        "    srand(0);\n",
        "    for (int i = 0; i < size; i++)\n",
        "    {\n",
        "        vector[i] = (int)(rand()) / RANDOM_MAX;\n",
        "    }\n",
        "}\n",
        "\n",
        "void sumOnHost(int *in1, int *in2, int *out, int size){\n",
        "    for (int i = 0; i < size; i++){\n",
        "        out[i] = (in1[i] + in2[i])/2;\n",
        "    }\n",
        "}\n",
        "\n",
        "// ############### Device(CPU) ###############\n",
        "// Hàm thực hiện reduce trên CPU\n",
        "__global__ void sumOnDevice(int *in1, int *in2, int *out, int size){\n",
        "    unsigned int idx = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "\n",
        "    if (idx < size){\n",
        "        out[idx] = (in1[idx] + in2[idx])/2;\n",
        "    }\n",
        "}\n",
        "bool checkResult(int *hostRef, int *gpuRef, unsigned int size)\n",
        "{\n",
        "    double epsilon = 1.0E-8;\n",
        "    bool isTrue = 1;\n",
        "\n",
        "    for (int i = 0; i < size; i++)\n",
        "    {\n",
        "        if (abs(hostRef[i] - gpuRef[i]) > epsilon)\n",
        "        {\n",
        "            printf(\"Arrays do not match!\\n\");\n",
        "            printf(\"host %5.2f gpu %5.2f at %d\\n\", hostRef[i], gpuRef[i], i);\n",
        "            isTrue = 0;\n",
        "            return isTrue;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return isTrue;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    printf(\"############ GPU Properties ############\\n\");\n",
        "    // Chọn GPU thực thi câu lệnh    \n",
        "    int dev = 0;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
        "    printf(\"Device %d: %s \\n\", dev, deviceProp.name);\n",
        "    CHECK(cudaSetDevice(dev));\n",
        "\n",
        "    // Khởi tạo kích thước vector\n",
        "    unsigned int size = 1 << 27; // 2^24 - Đổi số nhỏ hơn để tính toán nhanh hơn\n",
        "    int *A, *B, *hostRef, *gpuRef;\n",
        "    size_t nBytes = size * sizeof(int);\n",
        "    A = (int *) malloc(nBytes);\n",
        "    B = (int *) malloc(nBytes);\n",
        "    hostRef = (int *) malloc(nBytes);\n",
        "    gpuRef = (int *) malloc(nBytes);\n",
        "    \n",
        "    initialVector(A, size);\n",
        "    initialVector(B, size);\n",
        "    printf(\"Kích thước mảng : %d\\n\", size);\n",
        "\n",
        "    // Biến tính thời gian chạy\n",
        "    double iStart, iElaps;\n",
        "\n",
        "    // Kernel được cấu hình với 1D grid và 1D blocks\n",
        "    dim3 blockSize (BLOCK_SIZE);\n",
        "    dim3 gridSize  ((size - 1) / blockSize.x + 1);\n",
        "    printf(\"Kích thước : <<<Grid (%d, %d), Block (%d, %d)>>>\\n\", blockSize.x, blockSize.y, gridSize.x, gridSize.y);\n",
        "    \n",
        "    // CPU ##########################################################\n",
        "    printf(\"ID| Kernel\\t\\t\\t\\t|Time \\t\\t| Sum result \\n\");\n",
        "    // ############ 1. sumOnHost #############\n",
        "    iStart = seconds();\n",
        "    sumOnHost(A, B, hostRef, size);\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"1 | sumOnHost \\t\\t\\t\\t| %f sec\\t\\n\", iElaps);\n",
        "\n",
        "    // GPU ##########################################################\n",
        "    // ############ 2. sumOnDeviceWithoutStream #############\n",
        "    // Cấp phát bộ nhớ trên device (GPU)\n",
        "    int *d_A = NULL, *d_B = NULL, *d_C = NULL;\n",
        "    CHECK(cudaMalloc((int**)&d_A, nBytes));\n",
        "    CHECK(cudaMalloc((int**)&d_B, nBytes));\n",
        "    CHECK(cudaMalloc((int**)&d_C, nBytes));\n",
        "    \n",
        "    iStart = seconds();\n",
        "\n",
        "    // Copy inputs to device\n",
        "    cudaMemcpy(d_A, A, nBytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, nBytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    sumOnDevice<<<gridSize, blockSize, 0, 0>>>(d_A, d_B, d_C, size);\n",
        "    cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);\n",
        "    iElaps = seconds() - iStart;\n",
        "    int isTrue = checkResult(hostRef, gpuRef, size);\n",
        "    printf(\"2 | sumOnDeviceWithoutStream \\t\\t| %f sec\\t| %d\\t\\n\", iElaps, isTrue);\n",
        "\n",
        "    // ############ 3. sumOnDevice2Stream #############\n",
        "    unsigned int nStream = 2;\n",
        "\n",
        "    int *h_A, *h_B, *h_hostRef, *h_gpuRef;\n",
        "    cudaHostAlloc(&h_A, nBytes, cudaHostAllocDefault);\n",
        "    cudaHostAlloc(&h_B, nBytes, cudaHostAllocDefault);\n",
        "    initialVector(h_A, size);\n",
        "    initialVector(h_B, size);\n",
        "    cudaHostAlloc(&h_hostRef, nBytes, cudaHostAllocDefault);\n",
        "    cudaHostAlloc(&h_gpuRef, nBytes, cudaHostAllocDefault);\n",
        "    memset(h_hostRef, 0, nBytes);\n",
        "    memset(h_gpuRef,  0, nBytes);\n",
        "\n",
        "    // Tạo stream\n",
        "    cudaStream_t stream1[nStream];\n",
        "    for (int i = 0; i < nStream; i++)\n",
        "        cudaStreamCreate(&stream1[i]);\n",
        "\n",
        "    int iSize = size/nStream;\n",
        "    int iBytes = iSize * sizeof(int);\n",
        "    \n",
        "    iStart = seconds();\n",
        "\n",
        "    for (int i = 0; i < nStream; ++i)\n",
        "    {\n",
        "        int ioffset = i * iSize;\n",
        "        CHECK(cudaMemcpyAsync(&d_A[ioffset], &h_A[ioffset], iBytes, cudaMemcpyHostToDevice, stream1[i]));\n",
        "        CHECK(cudaMemcpyAsync(&d_B[ioffset], &h_B[ioffset], iBytes, cudaMemcpyHostToDevice, stream1[i]));\n",
        "        sumOnDevice<<<gridSize, blockSize, 0, stream1[i]>>>(&d_A[ioffset], &d_B[ioffset], &d_C[ioffset], iSize);\n",
        "        CHECK(cudaMemcpyAsync(&h_gpuRef[ioffset], &d_C[ioffset], iBytes, cudaMemcpyDeviceToHost, stream1[i]));\n",
        "    }\n",
        "\n",
        "    iElaps = seconds() - iStart;\n",
        "    isTrue = checkResult(hostRef, gpuRef, size);\n",
        "    printf(\"3 | sumOnDevice2Stream \\t\\t\\t| %f sec\\t| %d\\t\\n\", iElaps, isTrue);\n",
        "    for (int i = 0; i <nStream; i++)\n",
        "        cudaStreamDestroy(stream1[i]);\n",
        "\n",
        "    // ############ 4. sumOnDevice3Stream #############\n",
        "    nStream = 3;\n",
        "\n",
        "    cudaHostAlloc(&h_A, nBytes, cudaHostAllocDefault);\n",
        "    cudaHostAlloc(&h_B, nBytes, cudaHostAllocDefault);\n",
        "    initialVector(h_A, size);\n",
        "    initialVector(h_B, size);\n",
        "    cudaHostAlloc(&h_hostRef, nBytes, cudaHostAllocDefault);\n",
        "    cudaHostAlloc(&h_gpuRef, nBytes, cudaHostAllocDefault);\n",
        "    memset(h_hostRef, 0, nBytes);\n",
        "    memset(h_gpuRef,  0, nBytes);\n",
        "\n",
        "    // Tạo stream\n",
        "    cudaStream_t stream2[nStream];\n",
        "    for (int i = 0; i < nStream; i++)\n",
        "        cudaStreamCreate(&stream2[i]);\n",
        "\n",
        "    iSize = size/nStream;\n",
        "    iBytes = iSize * sizeof(int);\n",
        "    \n",
        "    iStart = seconds();\n",
        "    \n",
        "    for (int i = 0; i < nStream; ++i){\n",
        "        int ioffset = i * iSize;\n",
        "        CHECK(cudaMemcpyAsync(&d_A[ioffset], &h_A[ioffset], iBytes, cudaMemcpyHostToDevice, stream2[i]));\n",
        "        CHECK(cudaMemcpyAsync(&d_B[ioffset], &h_B[ioffset], iBytes, cudaMemcpyHostToDevice, stream2[i]));\n",
        "        sumOnDevice<<<gridSize, blockSize, 0, stream2[i]>>>(&d_A[ioffset], &d_B[ioffset], &d_C[ioffset], iSize);\n",
        "        CHECK(cudaMemcpyAsync(&h_gpuRef[ioffset], &d_C[ioffset], iBytes, cudaMemcpyDeviceToHost, stream2[i]));\n",
        "    }\n",
        "\n",
        "    iElaps = seconds() - iStart;\n",
        "    isTrue = checkResult(hostRef, gpuRef, size);\n",
        "    printf(\"4 | sumOnDevice3Stream \\t\\t\\t| %f sec\\t| %d\\t\\n\", iElaps, isTrue);\n",
        "    for (int i = 0; i <nStream; i++)\n",
        "        cudaStreamDestroy(stream2[i]);\n",
        "\n",
        "    // ############ 5. sumOnDevice3StreamUseEvent #############\n",
        "    // nStream = 3;\n",
        "    // Tạo stream\n",
        "    cudaStream_t stream3[nStream];\n",
        "    for (int i = 0; i < nStream; i++)\n",
        "        cudaStreamCreate(&stream3[i]);\n",
        "\n",
        "    cudaEvent_t *kernelEvent;\n",
        "    kernelEvent = (cudaEvent_t *) malloc(nStream * sizeof(cudaEvent_t));\n",
        "\n",
        "    for (int i = 0; i < nStream; i++){\n",
        "        CHECK(cudaEventCreateWithFlags(&(kernelEvent[i]), cudaEventDisableTiming));\n",
        "    }\n",
        "\n",
        "    iSize = size/nStream;\n",
        "    iBytes = iSize * sizeof(int);\n",
        "    \n",
        "    iStart = seconds();\n",
        "    \n",
        "    for (int i = 0; i < nStream; ++i){\n",
        "        int ioffset = i * iSize;\n",
        "        CHECK(cudaMemcpyAsync(&d_A[ioffset], &h_A[ioffset], iBytes, cudaMemcpyHostToDevice, stream3[i]));\n",
        "        CHECK(cudaMemcpyAsync(&d_B[ioffset], &h_B[ioffset], iBytes, cudaMemcpyHostToDevice, stream3[i]));\n",
        "        sumOnDevice<<<gridSize, blockSize, 0, stream3[i]>>>(&d_A[ioffset], &d_B[ioffset], &d_C[ioffset], iSize);\n",
        "        CHECK(cudaMemcpyAsync(&h_gpuRef[ioffset], &d_C[ioffset], iBytes, cudaMemcpyDeviceToHost, stream3[i]));\n",
        "        CHECK(cudaEventRecord(kernelEvent[i], stream3[i]));\n",
        "        CHECK(cudaStreamWaitEvent(stream3[nStream - 1], kernelEvent[i], 0));\n",
        "    }\n",
        "\n",
        "    iElaps = seconds() - iStart;\n",
        "    isTrue = checkResult(hostRef, gpuRef, size);\n",
        "    printf(\"5 | sumOnDevice3StreamUseEvent \\t\\t| %f sec\\t| %d\\t\\n\", iElaps, isTrue);\n",
        "    for (int i = 0; i <nStream; i++){\n",
        "        CHECK(cudaStreamDestroy(stream3[i]));\n",
        "        CHECK(cudaEventDestroy(kernelEvent[i]));\n",
        "    }\n",
        "  \n",
        "    // free device memory\n",
        "    CHECK(cudaFree(d_A));\n",
        "    CHECK(cudaFree(d_B));\n",
        "    CHECK(cudaFree(d_C));\n",
        "\n",
        "    // free pinned memory\n",
        "    CHECK(cudaFreeHost(h_A));\n",
        "    CHECK(cudaFreeHost(h_B));\n",
        "    CHECK(cudaFreeHost(h_hostRef));\n",
        "    CHECK(cudaFreeHost(h_gpuRef));\n",
        "\n",
        "    // free host memory\n",
        "    free(A);\n",
        "    free(B);\n",
        "    free(hostRef);\n",
        "    free(gpuRef);\n",
        "    free(kernelEvent);\n",
        "\n",
        "    // reset device\n",
        "    CHECK(cudaDeviceReset());\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############ GPU Properties ############\n",
            "Device 0: Tesla P100-PCIE-16GB \n",
            "Kích thước mảng : 134217728\n",
            "Kích thước : <<<Grid (512, 1), Block (262144, 1)>>>\n",
            "ID| Kernel\t\t\t\t|Time \t\t| Sum result \n",
            "1 | sumOnHost \t\t\t\t| 0.743230 sec\t\n",
            "2 | sumOnDeviceWithoutStream \t\t| 0.508454 sec\t| 1\t\n",
            "3 | sumOnDevice2Stream \t\t\t| 0.000163 sec\t| 1\t\n",
            "4 | sumOnDevice3Stream \t\t\t| 0.000117 sec\t| 1\t\n",
            "5 | sumOnDevice3StreamUseEvent \t\t| 0.000151 sec\t| 1\t\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9tWDDxnhLHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}