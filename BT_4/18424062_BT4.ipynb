{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "18424062_BT4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XFEzNQBb2wHF"
      },
      "source": [
        "# Bài tập 4 : Tính tổng tích luỹ (tt)\n",
        "\n",
        "**Thông tin sinh viên** :\n",
        "\n",
        "Hoàng Minh Thanh (18424062)\n",
        "\n",
        "Jupyter notebook (Online) : https://colab.research.google.com/drive/1TeARxOiMfQQ4AT8Gy61KvgNprqs5UIme\n",
        "\n",
        "Thực hiện chạy trên Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YF4ioW3H7k_Y"
      },
      "source": [
        "## Cài đặt cấu hình chạy CUDA trên Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48CqrfEDf6Ff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "a0429a1e-f400-401a-e8b8-f27f84eaa1b2"
      },
      "source": [
        "%%bash\n",
        "rm -r /content/*\n",
        "pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "nvcc --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-29rktwmd\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py): started\n",
            "  Building wheel for NVCCPlugin (setup.py): finished with status 'done'\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=9a5a1958272695233e8bbae8d624f4657e394baa61bb92d7cd20f5fbf48705f4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uy1642yf/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-29rktwmd\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lflYvWi_18A7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7d5f0f13-2224-45fd-eabb-38825c536358"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g5eHVcvg_3A",
        "colab_type": "text"
      },
      "source": [
        "Source code tham khảo : https://github.com/hmthanh/ProfessionalCUDACProgramming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UfRbHHPLOGR0"
      },
      "source": [
        "## 1. Cài đặt chương trình CUDA\n",
        "\n",
        "### Cài đặt chương trình tổng vector với các hàm khác nhau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jQaNUnaMTQEJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "ca411f65-5db8-48ac-a46c-e9d4568b78d6"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// ############### COMMON ###############\n",
        "#define CHECK(call)                                                        \\\n",
        "{                                                                          \\\n",
        "    const cudaError_t error = call;                                        \\\n",
        "    if (error != cudaSuccess)                                              \\\n",
        "    {                                                                      \\\n",
        "        printf(\"Error: %s:%d, \", __FILE__, __LINE__);                      \\\n",
        "        printf(\"code:%d, reason: %s\\n\", error, cudaGetErrorString(error)); \\\n",
        "        exit(1);                                                           \\\n",
        "    }                                                                      \\\n",
        "}\n",
        "\n",
        "inline double seconds()\n",
        "{\n",
        "    struct timeval tp;\n",
        "    struct timezone tzp;\n",
        "    int i = gettimeofday(&tp, &tzp);\n",
        "    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n",
        "}\n",
        "\n",
        "void initialData(double *data, int size)\n",
        "// Khởi tạo vector ban đầu có kích thước size, kiểu double và giá random trong khoảng [0, 1]\n",
        "{\n",
        "    srand(0);\n",
        "    for (int i = 0; i < size; i++)\n",
        "    {\n",
        "        data[i] = (double)(rand()) / RAND_MAX;\n",
        "    }\n",
        "}\n",
        "\n",
        "double sumGPU(double *data, int size){\n",
        "    double sum = 0;\n",
        "    for(int i = 0; i < size; i++){\n",
        "        sum += data[i];\n",
        "    }\n",
        "\n",
        "    return sum;\n",
        "}\n",
        "\n",
        "// ############### Device(CPU) ###############\n",
        "// Hàm thực hiện reduce trên CPU\n",
        "double recursiveReduce(double *data, int const size)\n",
        "{\n",
        "    if (size == 1) return data[0];\n",
        "  \n",
        "    int const stride = size / 2;\n",
        "    for (int i = 0; i < stride; i++){\n",
        "        data[i] += data[i + stride];\n",
        "    }\n",
        "    \n",
        "    return recursiveReduce(data, stride);\n",
        "}\n",
        "\n",
        "// ############### Device(GPU) ###############\n",
        "// Neighbored Pair phân kỳ\n",
        "__global__ void reduceNeighbored (double *g_idata, double *g_odata,\n",
        "    unsigned int n)\n",
        "{\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Chuyển từ con trỏ toàn cục sang con trỏ của block này\n",
        "    double *idata = g_idata + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Kiểm tra nếu vượt qua kích thước mảng\n",
        "    if (idx >= n) return;\n",
        "\n",
        "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
        "    for (int stride = 1; stride < blockDim.x; stride *= 2)\n",
        "    {\n",
        "        if ((tid % (2 * stride)) == 0)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // Đồng bộ hóa trong một threadBlock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Ghi kết quả cho block này vào bộ nhớ toàn cục\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "// Neighbored Pair cài đặt với ít phân kỳ bằng cách thực thi trong một block\n",
        "__global__ void reduceNeighboredLess (double *g_idata, double *g_odata,\n",
        "    unsigned int n)\n",
        "{\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Chuyển từ con trỏ toàn cục sang con trỏ của block này\n",
        "    double *idata = g_idata + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Kiểm tra nếu vượt qua kích thước mảng\n",
        "    if(idx >= n) return;\n",
        "\n",
        "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
        "    for (int stride = 1; stride < blockDim.x; stride *= 2)\n",
        "    {\n",
        "        // Chuyển tid sang bộ nhớ của một block (register - thanh ghi)\n",
        "        int index = 2 * stride * tid;\n",
        "\n",
        "        if (index < blockDim.x)\n",
        "        {\n",
        "            idata[index] += idata[index + stride];\n",
        "        }\n",
        "\n",
        "        // Đồng bộ hóa trong một threadBlock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Ghi kết quả cho block này vào bộ nhớ toàn cục\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "// Interleaved Pair Implementation with less divergence\n",
        "__global__ void reduceInterleaved (double *g_idata, double *g_odata, unsigned int n)\n",
        "{\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Chuyển từ con trỏ toàn cục sang con trỏ của block này\n",
        "    double *idata = g_idata + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Kiểm tra nếu vượt qua kích thước mảng\n",
        "    if(idx >= n) return;\n",
        "\n",
        "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Ghi kết quả cho block này vào bộ nhớ toàn cục\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrolling2 (double *g_idata, double *g_odata,\n",
        "    unsigned int n)\n",
        "{\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 2 + threadIdx.x;\n",
        "\n",
        "    // Chuyển từ con trỏ toàn cục sang con trỏ của block này\n",
        "    double *idata = g_idata + blockIdx.x * blockDim.x * 2;\n",
        "\n",
        "    // unrolling 2 data blocks\n",
        "    if (idx + blockDim.x < n) g_idata[idx] += g_idata[idx + blockDim.x];\n",
        "    // Đồng bộ hóa các group data trong 2 thread kết cận\n",
        "    __syncthreads();\n",
        "\n",
        "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // Đồng bộ hóa trong một threadBlock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Ghi kết quả cho block này vào bộ nhớ toàn cục\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrolling4(double *g_idata, double *g_odata, unsigned int n){\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 4 + threadIdx.x;\n",
        "\n",
        "    // Chuyển từ con trỏ toàn cục sang con trỏ của block này\n",
        "    double *idata = g_idata + blockIdx.x * blockDim.x * 4;\n",
        "\n",
        "    // unrolling 4\n",
        "    if (idx + 3 * blockDim.x < n)\n",
        "    {\n",
        "        double a1 = g_idata[idx];\n",
        "        double a2 = g_idata[idx + blockDim.x];\n",
        "        double a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        double a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4;\n",
        "    }\n",
        "    __syncthreads(); // Đồng bộ hóa các group data trong 4 thread kết cận\n",
        "\n",
        "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // Đồng bộ hóa trong một threadBlock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Ghi kết quả cho block này vào bộ nhớ toàn cục\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrolling8 (double *g_idata, double *g_odata, unsigned int n){\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
        "    double *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
        "\n",
        "    // unrolling 8\n",
        "    if (idx + 7 * blockDim.x < n)\n",
        "    {\n",
        "        double a1 = g_idata[idx];\n",
        "        double a2 = g_idata[idx + blockDim.x];\n",
        "        double a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        double a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        double b1 = g_idata[idx + 4 * blockDim.x];\n",
        "        double b2 = g_idata[idx + 5 * blockDim.x];\n",
        "        double b3 = g_idata[idx + 6 * blockDim.x];\n",
        "        double b4 = g_idata[idx + 7 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
        "    }\n",
        "    __syncthreads(); // Đồng bộ hóa các group data trong 8 thread kết cận\n",
        "\n",
        "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1){\n",
        "        if (tid < stride){\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // Đồng bộ hóa trong một threadBlock\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrollWarps8 (double *g_idata, double *g_odata, unsigned int n)\n",
        "{\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
        "    double *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
        "\n",
        "    if (idx + 7 * blockDim.x < n)\n",
        "    {\n",
        "        double a1 = g_idata[idx];\n",
        "        double a2 = g_idata[idx + blockDim.x];\n",
        "        double a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        double a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        double b1 = g_idata[idx + 4 * blockDim.x];\n",
        "        double b2 = g_idata[idx + 5 * blockDim.x];\n",
        "        double b3 = g_idata[idx + 6 * blockDim.x];\n",
        "        double b4 = g_idata[idx + 7 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
        "    for (int stride = blockDim.x / 2; stride > 32; stride >>= 1){\n",
        "        if (tid < stride){\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // Đồng bộ hóa trong một threadBlock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // unrolling warp\n",
        "    if (tid < 32)\n",
        "    {\n",
        "        volatile double *vmem = idata;\n",
        "        vmem[tid] += vmem[tid + 32];\n",
        "        vmem[tid] += vmem[tid + 16];\n",
        "        vmem[tid] += vmem[tid +  8];\n",
        "        vmem[tid] += vmem[tid +  4];\n",
        "        vmem[tid] += vmem[tid +  2];\n",
        "        vmem[tid] += vmem[tid +  1];\n",
        "    }\n",
        "\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceCompleteUnrollWarps8 (double *g_idata, double *g_odata,\n",
        "        unsigned int n){\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
        "    double *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
        "\n",
        "    if (idx + 7 * blockDim.x < n)\n",
        "    {\n",
        "        double a1 = g_idata[idx];\n",
        "        double a2 = g_idata[idx + blockDim.x];\n",
        "        double a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        double a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        double b1 = g_idata[idx + 4 * blockDim.x];\n",
        "        double b2 = g_idata[idx + 5 * blockDim.x];\n",
        "        double b3 = g_idata[idx + 6 * blockDim.x];\n",
        "        double b4 = g_idata[idx + 7 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
        "    }\n",
        "    __syncthreads(); // Đồng bộ hóa tất cả các thread trong một block\n",
        "\n",
        "    // in-place reduction and complete unroll\n",
        "    if (blockDim.x >= 1024 && tid < 512) idata[tid] += idata[tid + 512];\n",
        "    __syncthreads();\n",
        "\n",
        "    if (blockDim.x >= 512 && tid < 256) idata[tid] += idata[tid + 256];\n",
        "    __syncthreads();\n",
        "\n",
        "    if (blockDim.x >= 256 && tid < 128) idata[tid] += idata[tid + 128];\n",
        "    __syncthreads();\n",
        "\n",
        "    if (blockDim.x >= 128 && tid < 64) idata[tid] += idata[tid + 64];\n",
        "    __syncthreads();\n",
        "\n",
        "    // unrolling warp\n",
        "    if (tid < 32)\n",
        "    {\n",
        "        volatile double *vsmem = idata;\n",
        "        vsmem[tid] += vsmem[tid + 32];\n",
        "        vsmem[tid] += vsmem[tid + 16];\n",
        "        vsmem[tid] += vsmem[tid +  8];\n",
        "        vsmem[tid] += vsmem[tid +  4];\n",
        "        vsmem[tid] += vsmem[tid +  2];\n",
        "        vsmem[tid] += vsmem[tid +  1];\n",
        "    }\n",
        "\n",
        "    // Ghi kết quả cho block này vào bộ nhớ toàn cục\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "template <unsigned int iBlockSize>\n",
        "__global__ void reduceCompleteUnroll(double *g_idata, double *g_odata,\n",
        "                                     unsigned int n)\n",
        "{\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
        "\n",
        "    // Chuyển từ con trỏ toàn cục sang con trỏ của block này\n",
        "    double *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
        "\n",
        "    // unrolling 8\n",
        "    if (idx + 7 * blockDim.x < n)\n",
        "    {\n",
        "        double a1 = g_idata[idx];\n",
        "        double a2 = g_idata[idx + blockDim.x];\n",
        "        double a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        double a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        double b1 = g_idata[idx + 4 * blockDim.x];\n",
        "        double b2 = g_idata[idx + 5 * blockDim.x];\n",
        "        double b3 = g_idata[idx + 6 * blockDim.x];\n",
        "        double b4 = g_idata[idx + 7 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
        "    }\n",
        "\n",
        "    __syncthreads(); // Đồng bộ tất các thread trong một block\n",
        "\n",
        "    // in-place reduction and complete unroll\n",
        "    if (iBlockSize >= 1024 && tid < 512) idata[tid] += idata[tid + 512];\n",
        "    __syncthreads();\n",
        "\n",
        "    if (iBlockSize >= 512 && tid < 256)  idata[tid] += idata[tid + 256];\n",
        "    __syncthreads();\n",
        "\n",
        "    if (iBlockSize >= 256 && tid < 128)  idata[tid] += idata[tid + 128];\n",
        "    __syncthreads();\n",
        "\n",
        "    if (iBlockSize >= 128 && tid < 64)   idata[tid] += idata[tid + 64];\n",
        "    __syncthreads();\n",
        "\n",
        "    // unrolling warp\n",
        "    if (tid < 32)\n",
        "    {\n",
        "        volatile double *vsmem = idata;\n",
        "        vsmem[tid] += vsmem[tid + 32];\n",
        "        vsmem[tid] += vsmem[tid + 16];\n",
        "        vsmem[tid] += vsmem[tid +  8];\n",
        "        vsmem[tid] += vsmem[tid +  4];\n",
        "        vsmem[tid] += vsmem[tid +  2];\n",
        "        vsmem[tid] += vsmem[tid +  1];\n",
        "    }\n",
        "\n",
        "    // Ghi kết quả cho block này vào bộ nhớ toàn cục\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrollWarps (double *g_idata, double *g_odata, unsigned int n)\n",
        "{\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 2 + threadIdx.x;\n",
        "\n",
        "    // Chuyển từ con trỏ toàn cục sang con trỏ của block này\n",
        "    double *idata = g_idata + blockIdx.x * blockDim.x * 2;\n",
        "\n",
        "    // unrolling 2\n",
        "    if (idx + blockDim.x < n) g_idata[idx] += g_idata[idx + blockDim.x];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // Thực hiện tính tổng ở bộ nhớ toàn cục\n",
        "    for (int stride = blockDim.x / 2; stride > 32; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // Đồng bộ hóa trong một threadBlock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // unrolling last warp\n",
        "    if (tid < 32)\n",
        "    {\n",
        "        volatile double *vsmem = idata;\n",
        "        vsmem[tid] += vsmem[tid + 32];\n",
        "        vsmem[tid] += vsmem[tid + 16];\n",
        "        vsmem[tid] += vsmem[tid +  8];\n",
        "        vsmem[tid] += vsmem[tid +  4];\n",
        "        vsmem[tid] += vsmem[tid +  2];\n",
        "        vsmem[tid] += vsmem[tid +  1];\n",
        "    }\n",
        "\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    printf(\"############ THÔNG TIN GPU ############\\n\");\n",
        "    // Chọn GPU thực thi câu lệnh    \n",
        "    int dev = 0;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
        "    printf(\"Device %d: %s \\n\", dev, deviceProp.name);\n",
        "    CHECK(cudaSetDevice(dev));\n",
        "\n",
        "    // Khởi tạo kích thước vector\n",
        "    int size = 1 << 24; // 2^24\n",
        "    printf(\"Kích thước mảng : %d\\n\", size);\n",
        "    \n",
        "    // Kernel được cấu hình với 1D grid và 1D blocks\n",
        "    int const BLOCK_SIZE = 512;\n",
        "    dim3 block (BLOCK_SIZE, 1); // Block size có kích thước 512 x 1 ~ (x, y)\n",
        "    dim3 grid  ((size + block.x - 1) / block.x, 1); // Grid size có kích thước ceil(size/block.x)\n",
        "    printf(\"Kích thước : <<<Grid (%d, %d), Block (%d, %d)>>>\\n\", block.x, block.y, grid.x, grid.y);\n",
        " \n",
        "    // Cấp phát bộ nhớ trên host (CPU)\n",
        "    size_t bytes = size * sizeof(double);\n",
        "    double *h_idata = (double *) malloc(bytes); // host input data\n",
        "    double *h_odata = (double *) malloc(grid.x * sizeof(double)); // host output data\n",
        "    double *temp    = (double *) malloc(bytes); // vùng nhớ tạp để copy input cho nhiều hàm thực thi khác nhau\n",
        " \n",
        "    initialData(h_idata, size);\n",
        "    // Copy vào biến temp để chạy với CPU\n",
        "    memcpy (temp, h_idata, bytes);\n",
        " \n",
        "    // Biến tính thời gian chạy\n",
        "    double iStart, iElaps;\n",
        "    double gpu_sum = 0.0; // hàm tính tổng kết quả trên GPU\n",
        "    double gpu_bytes = grid.x * sizeof(double);\n",
        "\n",
        "    // Cấp phát bộ nhớ trên device (GPU)\n",
        "    double *d_idata = NULL;\n",
        "    double *d_odata = NULL;\n",
        "    CHECK(cudaMalloc(&d_idata, bytes));\n",
        "    CHECK(cudaMalloc(&d_odata, gpu_bytes));\n",
        " \n",
        "    printf(\"ID| Time \\t\\t| Sum result \\t\\t| <<<GridSize, BlockSize >>> | Kernel\\t\\t\\n\");\n",
        "    // ############ 1. CPU #############\n",
        "    iStart = seconds();\n",
        "    double cpu_sum = recursiveReduce (temp, size);\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"1 | %f sec\\t| %f\\t|\\t\\t | recursiveReduce-CPU\\n\", iElaps, cpu_sum);\n",
        "\n",
        "    // ############ 2. reduceNeighbored ############\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceNeighbored<<<grid, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, gpu_bytes, cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = sumGPU(h_odata, grid.x);\n",
        "    printf(\"2 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceNeighbored\\n\", iElaps, gpu_sum, grid.x, block.x);\n",
        "\n",
        "    // ############ 3. reduceNeighboredLess ############\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceNeighboredLess<<<grid, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, gpu_bytes, cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = sumGPU(h_odata, grid.x);\n",
        "    printf(\"3 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceNeighboredLess\\n\", iElaps, gpu_sum, grid.x, block.x);\n",
        "\n",
        "    // ############ 4. reduceInterleaved ############\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceInterleaved<<<grid, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, gpu_bytes, cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = sumGPU(h_odata, grid.x);\n",
        "    printf(\"4 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceInterleaved\\n\", iElaps, gpu_sum, grid.x, block.x);\n",
        "\n",
        "    // ############ 5. reduceUnrolling2 ############\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceUnrolling2<<<grid.x / 2, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 2 * sizeof(double), cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = sumGPU(h_odata, grid.x / 2);\n",
        "    printf(\"5 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceUnrolling2\\n\", iElaps, gpu_sum, grid.x/2, block.x);\n",
        "\n",
        "    // ############ 6. reduceUnrolling4 ############\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceUnrolling4<<<grid.x / 4, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 4 * sizeof(double), cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = sumGPU(h_odata, grid.x / 4);\n",
        "    printf(\"6 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceUnrolling4\\n\", iElaps, gpu_sum, grid.x/4, block.x);\n",
        "\n",
        "    // ############ 7. reduceUnrolling8 ############\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceUnrolling8<<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(double), cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = sumGPU(h_odata, grid.x / 8);\n",
        "    printf(\"7 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceUnrolling8\\n\", iElaps, gpu_sum, grid.x/8, block.x);\n",
        "\n",
        "    // ############ 8. reduceUnrollWarps8 ############\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceUnrollWarps8<<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(double), cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = sumGPU(h_odata, grid.x / 8);\n",
        "    printf(\"8 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceUnrollWarps8\\n\", iElaps, gpu_sum, grid.x/8, block.x);\n",
        "\n",
        "    // ############ 9. reduceCompleteUnrollWarsp8 ############\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceCompleteUnrollWarps8<<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(double), cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = sumGPU(h_odata, grid.x / 8);\n",
        "    printf(\"9 | %f sec\\t| %f\\t|<<<%d, %d>>> | reduceCompleteUnrollWarsp8\\n\", iElaps, gpu_sum, grid.x/8, block.x);\n",
        "\n",
        "    // ############ 10. reduceCompleteUnroll ############\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    switch (BLOCK_SIZE){\n",
        "    case 1024:\n",
        "        reduceCompleteUnroll<1024><<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "        break;\n",
        "\n",
        "    case 512:\n",
        "        reduceCompleteUnroll<512><<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "        break;\n",
        "\n",
        "    case 256:\n",
        "        reduceCompleteUnroll<256><<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "        break;\n",
        "\n",
        "    case 128:\n",
        "        reduceCompleteUnroll<128><<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "        break;\n",
        "\n",
        "    case 64:\n",
        "        reduceCompleteUnroll<64><<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "        break;\n",
        "    }\n",
        "\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(double), cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = sumGPU(h_odata, grid.x / 8);\n",
        "    printf(\"10| %f sec\\t| %f\\t|<<<%d, %d>>> | reduceCompleteUnroll\\n\", iElaps, gpu_sum, grid.x/8, block.x);\n",
        "\n",
        "    // free host memory\n",
        "    free(h_idata);\n",
        "    free(h_odata);\n",
        "\n",
        "    // free device memory\n",
        "    CHECK(cudaFree(d_idata));\n",
        "    CHECK(cudaFree(d_odata));\n",
        "\n",
        "    // reset device\n",
        "    CHECK(cudaDeviceReset());\n",
        "\n",
        "    // Print sum result\n",
        "    printf(\"Sum on CPU : %f\\nSum on GPU : %f\", cpu_sum, gpu_sum);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############ THÔNG TIN GPU ############\n",
            "Device 0: Tesla P100-PCIE-16GB \n",
            "Kích thước mảng : 16777216\n",
            "Kích thước : <<<Grid (512, 1), Block (32768, 1)>>>\n",
            "ID| Time \t\t| Sum result \t\t| <<<GridSize, BlockSize >>> | Kernel\t\t\n",
            "1 | 0.050493 sec\t| 8389084.624453\t|\t\t | recursiveReduce-CPU\n",
            "2 | 0.002042 sec\t| 8389084.624453\t|<<<32768, 512>>> | reduceNeighbored\n",
            "3 | 0.001141 sec\t| 8389084.624453\t|<<<32768, 512>>> | reduceNeighboredLess\n",
            "4 | 0.000958 sec\t| 8389084.624453\t|<<<32768, 512>>> | reduceInterleaved\n",
            "5 | 0.000619 sec\t| 8389084.624453\t|<<<16384, 512>>> | reduceUnrolling2\n",
            "6 | 0.000380 sec\t| 8389084.624453\t|<<<8192, 512>>> | reduceUnrolling4\n",
            "7 | 0.000318 sec\t| 8389084.624453\t|<<<4096, 512>>> | reduceUnrolling8\n",
            "8 | 0.000308 sec\t| 8389084.624453\t|<<<4096, 512>>> | reduceUnrollWarps8\n",
            "9 | 0.000307 sec\t| 8389084.624453\t|<<<4096, 512>>> | reduceCompleteUnrollWarsp8\n",
            "10| 0.000307 sec\t| 8389084.624453\t|<<<4096, 512>>> | reduceCompleteUnroll\n",
            "Sum on CPU : 8389084.624453\n",
            "Sum on GPU : 8389084.624453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KBj0mTbo8JrV"
      },
      "source": [
        "# 2. Báo cáo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g7J-PwhQ8P86"
      },
      "source": [
        "Có thể thấy để tối ưu quá trình tính toán ta có nhiều cách khác nhau như :\n",
        "* unroll trên block\n",
        "* unroll trên một wrap\n",
        "* sử dụng template function\n",
        "* sử dụng kỹ thuật stride\n",
        "* sử dụng kỹ thuật stride để tránh phân mảnh\n",
        "\n",
        "Mỗi một câu lệnh đều có thể ảnh hưởng đến hiệu suất tính toán.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9jbDOuHI-Re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umcg2mKlEajX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}