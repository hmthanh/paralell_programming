{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "18424062_TH01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XFEzNQBb2wHF"
      },
      "source": [
        "# Bài tập 2 : Bài toán cộng hai vector\n",
        "**Thông tin sinh viên** :\n",
        "\n",
        "Hoàng Minh Thanh (18424062)\n",
        "\n",
        "Jupyter notebook (Online) : https://colab.research.google.com/drive/189f2vZtNKGjc5oc5T6dkOJOVClT4rnS1\n",
        "\n",
        "Thực hiện chạy trên Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YF4ioW3H7k_Y"
      },
      "source": [
        "Cài đặt plugin chạy GPU trên Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lflYvWi_18A7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "521860f0-9299-4133-b48a-f107007cd022"
      },
      "source": [
        "%%bash\n",
        "nvcc --version\n",
        "rm -rf /content/*\n",
        "pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-3pabvnts\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py): started\n",
            "  Building wheel for NVCCPlugin (setup.py): finished with status 'done'\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=beb7af5bbc89ed87a4ca76286fc8d0fb98af50bc7cf0a15e431563e374f66e1a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p2h0qs5z/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-3pabvnts\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IkSmNRuv794i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8eed4d6d-c66b-464d-d87a-b113cfd944d6"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9qzonG0Jbsy",
        "colab_type": "text"
      },
      "source": [
        "Tải github private repository chứa file in.pnm cần lấy và các file khác\n",
        "\n",
        "Vì đây là private repository nên phải cấu hình clone bằng ssh\n",
        "\n",
        "Tham khảo tại : https://towardsdatascience.com/using-git-with-colab-via-ssh-175e8f3751ec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV19gNnhNzsG",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "96f83a1c-da06-498c-b541-b6660d5abe77"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/\")\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-01b1036a-62bb-40bb-a45c-c964b325ac37\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-01b1036a-62bb-40bb-a45c-c964b325ac37\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ssh.tar.gz to ssh.tar.gz\n",
            "ssh.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWCypga3OKi8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "227d2f36-d731-4c85-90a8-9599963be4b6"
      },
      "source": [
        "%%bash\n",
        "rm -rf /root/.ssh\n",
        "mkdir /root/.ssh\n",
        "\n",
        "tar xvzf ssh.tar.gz\n",
        "cp ssh-colab/* /root/.ssh && rm -rf ssh-colab && rm -rf ssh.tar.gz\n",
        "chmod 700 /root/.ssh\n",
        "\n",
        "touch /root/.ssh/known_hosts\n",
        "ssh-keyscan github.com >> /root/.ssh/known_hosts\n",
        "chmod 644 /root/.ssh/known_hosts\n",
        "chmod 400 /root/.ssh/id_rsa_thanh"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ssh-colab/\n",
            "ssh-colab/config\n",
            "ssh-colab/id_rsa_thanh\n",
            "ssh-colab/id_rsa_thanh.pub\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "# github.com:22 SSH-2.0-babeld-9389d978\n",
            "# github.com:22 SSH-2.0-babeld-9389d978\n",
            "# github.com:22 SSH-2.0-babeld-9389d978\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APLvDoUmLzpC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ba8c9a0f-e5c2-4895-fd58-49dd0a2f4a37"
      },
      "source": [
        "%%bash\n",
        "git config --global user.email \"hmthanhgm@gmail.com\"\n",
        "git config --global user.name \"hmthanh\"\n",
        "\n",
        "ssh-agent /bin/bash\n",
        "git clone git@github.com:hmthanh/paralell_programming.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'paralell_programming'...\n",
            "Warning: Permanently added the RSA host key for IP address '140.82.112.3' to the list of known hosts.\r\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0vLs0l8Sebp",
        "colab_type": "text"
      },
      "source": [
        "Di chuyển các file cần thiết ra /content/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7oQ6kRjSir2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "mv /content/paralell_programming/Practical_1/* /content/\n",
        "rm -rf /content/paralell_programming/"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UfRbHHPLOGR0"
      },
      "source": [
        "## Cài đặt chương trình\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jQaNUnaMTQEJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "9440d35f-6dc3-4f10-b238-5a423d8b88c9"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdint.h>\n",
        "#include <string.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#define CHECK(call)                                                            \\\n",
        "{                                                                              \\\n",
        "    const cudaError_t error = call;                                            \\\n",
        "    if (error != cudaSuccess)                                                  \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n",
        "        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n",
        "                cudaGetErrorString(error));                                    \\\n",
        "        exit(EXIT_FAILURE);                                                    \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "struct GpuTimer\n",
        "{\n",
        "    cudaEvent_t start;\n",
        "    cudaEvent_t stop;\n",
        "\n",
        "    GpuTimer()\n",
        "    {\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "    }\n",
        "\n",
        "    ~GpuTimer()\n",
        "    {\n",
        "        cudaEventDestroy(start);\n",
        "        cudaEventDestroy(stop);\n",
        "    }\n",
        "\n",
        "    void Start()\n",
        "    {\n",
        "        cudaEventRecord(start, 0);\n",
        "    }\n",
        "\n",
        "    void Stop()\n",
        "    {\n",
        "        cudaEventRecord(stop, 0);\n",
        "    }\n",
        "\n",
        "    float Elapsed()\n",
        "    {\n",
        "        float elapsed;\n",
        "        cudaEventSynchronize(stop);\n",
        "        cudaEventElapsedTime(&elapsed, start, stop);\n",
        "        return elapsed;\n",
        "    }\n",
        "};\n",
        "\n",
        "void readPnm(char * fileName, int &width, int &height, uchar3 * &pixels)\n",
        "{\n",
        "\tFILE * f = fopen(fileName, \"r\");\n",
        "\tif (f == NULL)\n",
        "\t{\n",
        "\t\tprintf(\"Cannot read %s\\n\", fileName);\n",
        "\t\texit(EXIT_FAILURE);\n",
        "\t}\n",
        "\n",
        "\tchar type[3];\n",
        "\tfscanf(f, \"%s\", type);\n",
        "\t\n",
        "\tif (strcmp(type, \"P3\") != 0) // In this exercise, we don't touch other types\n",
        "\t{\n",
        "\t\tfclose(f);\n",
        "\t\tprintf(\"Cannot read %s\\n\", fileName); \n",
        "\t\texit(EXIT_FAILURE); \n",
        "\t}\n",
        "\n",
        "\tfscanf(f, \"%i\", &width);\n",
        "\tfscanf(f, \"%i\", &height);\n",
        "\t\n",
        "\tint max_val;\n",
        "\tfscanf(f, \"%i\", &max_val);\n",
        "\tif (max_val > 255) // In this exercise, we assume 1 byte per value\n",
        "\t{\n",
        "\t\tfclose(f);\n",
        "\t\tprintf(\"Cannot read %s\\n\", fileName); \n",
        "\t\texit(EXIT_FAILURE); \n",
        "\t}\n",
        "\n",
        "\tpixels = (uchar3 *)malloc(width * height * sizeof(uchar3));\n",
        "\tfor (int i = 0; i < width * height; i++)\n",
        "\t\tfscanf(f, \"%hhu%hhu%hhu\", &pixels[i].x, &pixels[i].y, &pixels[i].z);\n",
        "\n",
        "\tfclose(f);\n",
        "}\n",
        "\n",
        "void writePnm(uchar3 * pixels, int width, int height, char * fileName)\n",
        "{\n",
        "\tFILE * f = fopen(fileName, \"w\");\n",
        "\tif (f == NULL)\n",
        "\t{\n",
        "\t\tprintf(\"Cannot write %s\\n\", fileName);\n",
        "\t\texit(EXIT_FAILURE);\n",
        "\t}\t\n",
        "\n",
        "\tfprintf(f, \"P3\\n%i\\n%i\\n255\\n\", width, height); \n",
        "\n",
        "\tfor (int i = 0; i < width * height; i++)\n",
        "\t\tfprintf(f, \"%hhu\\n%hhu\\n%hhu\\n\", pixels[i].x, pixels[i].y, pixels[i].z);\n",
        "\t\n",
        "\tfclose(f);\n",
        "}\n",
        "\n",
        "__global__ void blurImgKernel(uchar3 *inPixels, int width, int height, \n",
        "\t\t\t\t\t\t\tfloat *filter, int filterWidth, \n",
        "\t\t\t\t\t\t\tuchar3 *outPixels)\n",
        "{\n",
        "\t// TODO\n",
        "\tint r = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\tint c = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\tif (r < height && c < width)\n",
        "\t{\n",
        "\t\tint i = r * width + c;\n",
        "\t\tfloat3 outPixel = make_float3(0, 0, 0);\n",
        "\t\tfor (int fR = 0; fR < filterWidth; fR++)\n",
        "\t\t{\n",
        "\t\t\tfor (int fC = 0; fC < filterWidth; fC++)\n",
        "\t\t\t{\n",
        "\t\t\t\tfloat filterVal = filter[fR * filterWidth + fC];\n",
        "\n",
        "\t\t\t\tint inPixelsR = (r - filterWidth/2) + fR;\n",
        "\t\t\t\tint inPixelsC = (c - filterWidth/2) + fC;\n",
        "\t\t\t\tinPixelsR = min(height - 1, max(0, inPixelsR)); \n",
        "\t\t\t\tinPixelsC = min(width - 1, max(0, inPixelsC)); \n",
        "\t\t\t\tuchar3 inPixel = inPixels[inPixelsR * width + inPixelsC];\n",
        "\t\t\t\t\n",
        "\t\t\t\toutPixel.x += filterVal * inPixel.x;\n",
        "\t\t\t\toutPixel.y += filterVal * inPixel.y;\n",
        "\t\t\t\toutPixel.z += filterVal * inPixel.z;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\n",
        "\t\toutPixels[i] = make_uchar3(outPixel.x, outPixel.y, outPixel.z);\n",
        "\t}\n",
        "}\n",
        "\n",
        "void blurImg(uchar3 * inPixels, int width, int height, float * filter, int filterWidth, \n",
        "\t\t\tuchar3 * outPixels,\n",
        "\t\t\tbool useDevice=false, dim3 blockSize=dim3(1, 1))\n",
        "{\n",
        "\tGpuTimer timer;\n",
        "\ttimer.Start();\n",
        "\tif (useDevice == false)\n",
        "\t{\n",
        "\t\tfor (int outPixelsR = 0; outPixelsR < height; outPixelsR++)\n",
        "\t\t{\n",
        "\t\t\tfor (int outPixelsC = 0; outPixelsC < width; outPixelsC++)\n",
        "\t\t\t{\n",
        "\t\t\t\tfloat3 outPixel = make_float3(0, 0, 0);\n",
        "\t\t\t\tfor (int filterR = 0; filterR < filterWidth; filterR++)\n",
        "\t\t\t\t{\n",
        "\t\t\t\t\tfor (int filterC = 0; filterC < filterWidth; filterC++)\n",
        "\t\t\t\t\t{\n",
        "\t\t\t\t\t\tfloat filterVal = filter[filterR * filterWidth + filterC];\n",
        "\n",
        "\t\t\t\t\t\tint inPixelsR = (outPixelsR - filterWidth/2) + filterR;\n",
        "\t\t\t\t\t\tint inPixelsC = (outPixelsC - filterWidth/2) + filterC;\n",
        "\t\t\t\t\t\tinPixelsR = min(height - 1, max(0, inPixelsR)); \n",
        "\t\t\t\t\t\tinPixelsC = min(width - 1, max(0, inPixelsC)); \n",
        "\t \t\t\t\t\tuchar3 inPixel = inPixels[inPixelsR * width + inPixelsC];\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\toutPixel.x += filterVal * inPixel.x;\n",
        "\t\t\t\t\t\toutPixel.y += filterVal * inPixel.y;\n",
        "\t\t\t\t\t\toutPixel.z += filterVal * inPixel.z;\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t}\n",
        "\t\t\t\toutPixels[outPixelsR * width + outPixelsC] = make_uchar3(outPixel.x, outPixel.y, outPixel.z);\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\telse // Use device\n",
        "\t{\n",
        "\t\t// Chọn GPU thực thi câu lệnh    \n",
        "\t\tint dev = 0;\n",
        "\t\tcudaDeviceProp devProp;\n",
        "\t\tcudaGetDeviceProperties(&devProp, dev);\n",
        "\t\tCHECK(cudaSetDevice(dev));\n",
        "\t\tprintf(\"GPU name: %s\\n\", devProp.name);\n",
        "\t\tprintf(\"GPU compute capability: %d.%d\\n\", devProp.major, devProp.minor);\n",
        "\n",
        "\t\t// TODO\n",
        "\t\t// Allocate device memories\n",
        "\t\tuchar3 *d_inPixels, *d_outPixels;\n",
        "\t\tfloat *d_filter;\n",
        "\t\tCHECK(cudaMalloc(&d_inPixels, width * height * 3 * sizeof(uchar3)));\n",
        "\t\tCHECK(cudaMalloc(&d_outPixels, width * height * 3 * sizeof(uchar3)));\n",
        "\t\tCHECK(cudaMalloc(&d_filter, filterWidth * filterWidth * sizeof(float)));\n",
        "\n",
        "\t\t// Copy data to device memory\n",
        "\t\tCHECK(cudaMemcpy(d_inPixels, inPixels, width * height * 3 * sizeof(uchar3), cudaMemcpyHostToDevice));\n",
        "\t\tCHECK(cudaMemcpy(d_filter, filter, filterWidth * filterWidth * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "\t\t// Call kernel\n",
        "\t\tdim3 gridSize((width - 1) / blockSize.x + 1, (height - 1) / blockSize.y + 1);\n",
        "\t\tblurImgKernel<<<gridSize, blockSize>>>(d_inPixels, width, height, d_filter, filterWidth, d_outPixels);\n",
        "\t\t\n",
        "\n",
        "\t\t// Copy result from device memory\n",
        "\t\tCHECK(cudaMemcpy(outPixels, d_outPixels, width * height * sizeof(uchar3), cudaMemcpyDeviceToHost));\n",
        "\n",
        "\t\t// Free device memories\n",
        "\t\tCHECK(cudaFree(d_inPixels));\n",
        "\t\tCHECK(cudaFree(d_outPixels));\n",
        "\t\tCHECK(cudaFree(d_filter));\n",
        "\t}\n",
        "\ttimer.Stop();\n",
        "\tfloat time = timer.Elapsed();\n",
        "\tprintf(\"Processing time (%s): %f ms\\n\\n\", \n",
        "    \t\tuseDevice == true? \"use device\" : \"use host\", time);\n",
        "}\n",
        "\n",
        "float computeError(uchar3 * a1, uchar3 * a2, int n)\n",
        "{\n",
        "\tfloat err = 0;\n",
        "\tfor (int i = 0; i < n; i++)\n",
        "\t{\n",
        "\t\terr += abs((int)a1[i].x - (int)a2[i].x);\n",
        "\t\terr += abs((int)a1[i].y - (int)a2[i].y);\n",
        "\t\terr += abs((int)a1[i].z - (int)a2[i].z);\n",
        "\t}\n",
        "\terr /= (n * 3);\n",
        "\treturn err;\n",
        "}\n",
        "\n",
        "char * concatStr(const char * s1, const char * s2)\n",
        "{\n",
        "    char * result = (char *)malloc(strlen(s1) + strlen(s2) + 1);\n",
        "    strcpy(result, s1);\n",
        "    strcat(result, s2);\n",
        "    return result;\n",
        "}\n",
        "\n",
        "// Vì chạy online trên Colab nên ta set sẵn các tham số\n",
        "int main() //int argc, char ** argv\n",
        "{\n",
        "\tint argc = 5;\n",
        "\tchar argv[5][255] = { \"./bt1\", \"/content/in.pnm\", \"/content/out.pnm\", \"32\", \"32\" };\n",
        "\t\n",
        "\tif (argc !=3 && argc != 5)\n",
        "\t{\n",
        "\t\tprintf(\"The number of arguments is invalid\\n\");\n",
        "\t\treturn EXIT_FAILURE;\n",
        "\t}\n",
        "\n",
        "\t// Read input image file\n",
        "\tint width, height;\n",
        "\tuchar3 * inPixels;\n",
        "\treadPnm(argv[1], width, height, inPixels);\n",
        "\tprintf(\"Image size (width x height): %i x %i\\n\\n\", width, height);\n",
        "\n",
        "\t// Set up a simple filter with blurring effect\n",
        "\tint filterWidth = 9;\n",
        "\tfloat *filter = (float *)malloc(filterWidth * filterWidth * sizeof(float));\n",
        "\tfor (int filterR = 0; filterR < filterWidth; filterR++)\n",
        "\t{\n",
        "\t\tfor (int filterC = 0; filterC < filterWidth; filterC++)\n",
        "\t\t{\n",
        "\t\t\tfilter[filterR * filterWidth + filterC] = 1. / (filterWidth * filterWidth);\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t// Blur input image not using device\n",
        "\tuchar3 * correctOutPixels= (uchar3 *)malloc(width * height * sizeof(uchar3)); \n",
        "\tblurImg(inPixels, width, height, filter, filterWidth, correctOutPixels);\n",
        "\t\n",
        "    // Blur input image using device\n",
        "\tuchar3 * outPixels= (uchar3 *)malloc(width * height * sizeof(uchar3));\n",
        "\tdim3 blockSize(32, 32); // Default\n",
        "\tif (argc == 5)\n",
        "\t{\n",
        "\t\tblockSize.x = atoi(argv[3]);\n",
        "\t\tblockSize.y = atoi(argv[4]);\n",
        "\t}\n",
        "\tblurImg(inPixels, width, height, filter, filterWidth, outPixels, true, blockSize);\n",
        "\n",
        "\t// Compute mean absolute error between host result and device result\n",
        "\tfloat err = computeError(outPixels, correctOutPixels, width * height);\n",
        "\tprintf(\"Error between device result and host result: %f\\n\", err);\n",
        "\n",
        "\t// Write results to files\n",
        "\tchar *outFileNameBase = strtok(argv[2], \".\"); // Get rid of extension\n",
        "\tprintf(\"outFileNameBase : %s\", outFileNameBase);\n",
        "\twritePnm(correctOutPixels, width, height, concatStr(outFileNameBase, \"_host.pnm\"));\n",
        "\twritePnm(outPixels, width, height, concatStr(outFileNameBase, \"_device.pnm\"));\n",
        "\n",
        "\t// Free memories\n",
        "\tfree(inPixels);\n",
        "\tfree(outPixels);\n",
        "\tfree(filter);\n",
        "}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Processing time (use host): 384.859680 ms\n",
            "\n",
            "GPU name: Tesla P100-PCIE-16GB\n",
            "GPU compute capability: 6.0\n",
            "Processing time (use device): 2.104704 ms\n",
            "\n",
            "Error between device result and host result: 0.000703\n",
            "outFileNameBase : /content/out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "735005Rto9LE",
        "colab_type": "text"
      },
      "source": [
        "# Thực thi với các kích thước filter khác nhau\n",
        "\n",
        "* Biên dịch file \"bt1.cu\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx_1ZSEBy8rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc bt1.cu -o bt1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nje3z2dj73-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "1b29cb43-e498-4dec-ab6b-0fdc0b9f6387"
      },
      "source": [
        "!./bt1 in.pnm out.pnm 32 16"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Processing time (use host): 385.448364 ms\n",
            "\n",
            "GPU name: Tesla P100-PCIE-16GB\n",
            "GPU compute capability: 6.0\n",
            "Processing time (use device): 2.096864 ms\n",
            "\n",
            "Error between device result and host result: 0.000703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqp4vG-E8GCx",
        "colab_type": "text"
      },
      "source": [
        "Như vậy có thể thấy kết quả nhỏ hơn 0.xxx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fSO8FvG8O5U",
        "colab_type": "text"
      },
      "source": [
        "* Thực thi với kích thước filter 8x8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY4mIJFV8gL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "c349460c-3639-4389-a7e3-95af9433cee0"
      },
      "source": [
        "!./bt1 in.pnm out.pnm 8 8"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Processing time (use host): 394.060913 ms\n",
            "\n",
            "GPU name: Tesla P100-PCIE-16GB\n",
            "GPU compute capability: 6.0\n",
            "Processing time (use device): 2.206176 ms\n",
            "\n",
            "Error between device result and host result: 0.000703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O4FljrsD8WkP"
      },
      "source": [
        "* Thực thi với kích thước filter 16 x 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wL0pPOA8itB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "59f1308c-d113-4461-e2c8-a9620c300b3f"
      },
      "source": [
        "!./bt1 in.pnm out.pnm 16 16"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Processing time (use host): 393.984985 ms\n",
            "\n",
            "GPU name: Tesla P100-PCIE-16GB\n",
            "GPU compute capability: 6.0\n",
            "Processing time (use device): 2.061920 ms\n",
            "\n",
            "Error between device result and host result: 0.000703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rWWFlO-P8XAY"
      },
      "source": [
        "* Thực thi với kích thước filter 32 x 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIC-JWoe8leh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "2a4bc6f0-fee0-4444-fffc-ed6504699723"
      },
      "source": [
        "!./bt1 in.pnm out.pnm 32 32"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Processing time (use host): 385.749817 ms\n",
            "\n",
            "GPU name: Tesla P100-PCIE-16GB\n",
            "GPU compute capability: 6.0\n",
            "Processing time (use device): 2.049952 ms\n",
            "\n",
            "Error between device result and host result: 0.000703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K1UDv2Cx8XC_"
      },
      "source": [
        "* Thực thi với kích thước filter 64 x 64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBoEbqYO7-A2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "521edfb1-b4ec-4be7-a7a2-84d0fd9a756a"
      },
      "source": [
        "!./bt1 in.pnm out.pnm 64 64"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Processing time (use host): 387.610596 ms\n",
            "\n",
            "GPU name: Tesla P100-PCIE-16GB\n",
            "GPU compute capability: 6.0\n",
            "Processing time (use device): 1.925440 ms\n",
            "\n",
            "Error between device result and host result: 124.033791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgo3EQ-A8ugA",
        "colab_type": "text"
      },
      "source": [
        "Có thể thấy độ lỗi lên đến **124.033791** khi thực thi với kích thước filter 64 x 64 đúng như với yêu cầu của thầy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAoISYbI80Zh",
        "colab_type": "text"
      },
      "source": [
        "### Giải thích :\n",
        "\n",
        "Xảy ra lỗi như vậy là do các thread của mỗi block được phân vào các wrap (32 thread) khác nhau.\n",
        "Trong GPU thì mỗi thread trong một wrap thực thi bất đồng bộ sử dụng chung một thanh nhớ register (bộ nhớ tạm trên cùng một wrap) nên có thể với kích thước filter lớn hơn 32 thì quá trình tính toán song song sẽ dấn đến một thread đã xử lý xong và cập nhật kết quả mới vào bộ nhớ toàn cục nhưng thread khác đang xử lý sẽ lấy kết quả pixels từ bộ nhớ tạm trên thanh ghi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6Hdg_7C8ohX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}